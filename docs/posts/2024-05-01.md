---
draft: true
date: 2024-05-01
authors:
  - ronald_luo
categories:
  - Records of Trivia
comments: true
---

# 数模校赛记录

(A题)题目分别给出了正常人、早期和晚期癌症患者的基因表达数据(一个数值)，然后大概需要分析出能够辨别癌症状态的特征基因，

而我觉得这题能可以使用神经网络来操作，所以就打算选这题尝试

>   另一方面也因为，B题是*基于负面影响最小的任务分配问题*，感觉没有太多可以操作的空间

<!-- more -->

我的想法是使用MLP来训练数据，但由于这题最后需要找出特征，而之前不太清楚要如何由已训练好的模型找到特征，所以搜寻信息

???+ example "对话记录"

    你:
    
    How to extract feature dimensions from DNN models?
    
    &nbsp;
    
    Bing:
    
    要通过深度学习来确定数据中哪些维度是重要的，可以采用以下方法：
    
    1.   [**特征重要性评估**：使用类似于XGBoost模型中的特征重要性计算方法。在深度神经网络（DNN）中，可以通过观察模型中每个特征的变化对模型性能的影响来评估特征的重要性。例如，可以通过随机打乱每个特征的值并重新评估模型性能来实现。如果性能下降显著，则该特征可能很重要](https://www.zhihu.com/question/310837513) [`¹`](https://www.zhihu.com/question/310837513) [`²`](https://blog.csdn.net/fengdu78/article/details/120735471)。
    
    2.   [**Shapley值**：Shapley值是一种博弈论中的概念，用于量化每个玩家（在这里是特征）对游戏（模型的预测）的贡献。在深度学习中，可以使用Shapley值来估计每个特征对模型预测的贡献](https://www.zhihu.com/question/310837513) [`¹`](https://www.zhihu.com/question/310837513)。
    
    3.   **正则化技术**：使用L1正则化可以帮助进行特征选择，因为它倾向于产生稀疏权重矩阵。在训练过程中，不重要的特征的权重会趋近于零。
    
    4.   **注意力机制**：在深度学习模型中，特别是在序列模型如RNN中，注意力机制可以用来识别对预测结果最有影响的输入部分。
    
    5.   **模型可解释性工具**：使用模型可解释性工具，如LIME或SHAP，可以帮助解释模型的预测，并指出哪些特征对预测结果有最大影响。
    
    通过这些方法，你可以识别出对模型预测最有影响的特征，即数据中的重要维度。这些方法可以单独使用，也可以结合使用，以获得更全面的特征重要性评估。
    
    了解详细信息 [`1 | zhihu.com`](https://www.zhihu.com/question/310837513) [`2 | blog.csdn.net`](https://blog.csdn.net/fengdu78/article/details/120735471) [`3 | zhuanlan.zhihu.com`](https://zhuanlan.zhihu.com/p/395560780) [`4 | bing.com`](https://bing.com/search?q=深度学习+如何获取数据重要维度) [`5 | zhuanlan.zhihu.com`](https://zhuanlan.zhihu.com/p/655633788)

查看了Bing提到的知乎上一个问题的回答，注意到这个回答提到了**==Shapley值==**

[使用DNN训练神经网络模型时，如何知道每个特征的重要性（像xgboost模型能计算出特征重要性一样）？ - 王睿的回答 - 知乎](https://www.zhihu.com/question/310837513/answer/1281609735)

而然后重新使用英文询问Bing，**也提到了Shapley值**

???+ example "对话记录"

    你:
    
    How to extract feature dimensions from DNN models?
    
    &nbsp;
    
    Bing:
    
    To extract feature dimensions from Deep Neural Network (DNN) models, you typically follow these steps:
    
    1.   **Choose the layer** from which you want to extract features. This is often a layer towards the end of the network, just before the fully connected layers, as it captures high-level features.
    2.   **Pass your input data** through the network up to the chosen layer. You can do this by modifying the network architecture to output the desired layer’s activations.
    3.   **Collect the output** of that layer, which will be the features. The shape of this output will give you the feature dimensions.
    
    For example, in Keras, you can use the `Model` class to create a new model that outputs the features from a specific layer:
    
    ```python
    from keras.models import Model
    
    # Assume 'base_model' is your pre-trained DNN model
    # and 'layer_name' is the name of the layer from which you want to extract features.
    
    model = Model(inputs=base_model.input, outputs=base_model.get_layer(layer_name).output)
    
    # Now you can use this model to predict and extract features
    features = model.predict(your_data)
    ```
    
    The `features` variable will now contain the output of the layer specified, and the shape of this array will give you the feature dimensions.
    
    For large datasets that don’t fit into memory, you can use **incremental learning**. [This involves extracting features in batches and possibly storing them on disk before training a classifier on top of these features](https://pyimagesearch.com/2019/05/27/keras-feature-extraction-on-large-datasets-with-deep-learning/) [`¹`](https://pyimagesearch.com/2019/05/27/keras-feature-extraction-on-large-datasets-with-deep-learning/).
    
    [If you’re working with Convolutional Neural Networks (CNNs), the filters in the convolutional layers act as feature extractors, capturing patterns such as edges and textures in the initial layers, and more complex features in deeper layers](https://medium.com/@leicao.me/how-deep-learning-neural-networks-extracts-features-277244bcf66e) [`²`](https://medium.com/@leicao.me/how-deep-learning-neural-networks-extracts-features-277244bcf66e).
    
    Remember, the exact method may vary depending on the framework you’re using and the specific architecture of your DNN model. The provided example is a general approach and might need adjustments based on your setup.
    
    了解详细信息 [`1 | pyimagesearch.com`](https://pyimagesearch.com/2019/05/27/keras-feature-extraction-on-large-datasets-with-deep-learning/) [`2 | medium.com`](https://medium.com/@leicao.me/how-deep-learning-neural-networks-extracts-features-277244bcf66e) [`3 | stats.stackexchange.com`](https://stats.stackexchange.com/questions/473667/feature-extraction-in-deep-neural-networks) [`4 | stackoverflow.com`](https://stackoverflow.com/questions/69298074/how-to-extract-features-from-a-cnn-model-using-its-actuall-weights-after-trainin) [`5 | nature.com`](https://www.nature.com/articles/s41598-018-34833-6.pdf)
    
    &nbsp;
    
    你:
    
    For example, I have a dataset with 10 dimensions each, which can be used to classify the data into one of three categories. How can I determine which dimension has the greatest impact on classification (using deep neural networks)
    
    &nbsp;
    
    Bing:

    To determine which dimension has the greatest impact on classification using deep neural networks, you can use techniques such as **permutation importance** or **SHAP (SHapley Additive exPlanations)** values. Here’s a brief overview of each method:

    <big>**Permutation Importance**</big>

    Permutation importance is a model inspection technique that can be used for any fitted estimator when the data is tabular. This method involves shuffling individual feature columns and observing the impact on the model’s accuracy. [The idea is that the features that are important to the model’s predictions will show a significant decrease in model performance when they are shuffled](https://stackoverflow.com/questions/45361559/feature-importance-chart-in-neural-network-using-keras-in-python) [`¹`](https://stackoverflow.com/questions/45361559/feature-importance-chart-in-neural-network-using-keras-in-python).

    Here’s how you can implement permutation importance using Python with Keras:

    ```python
    from keras.wrappers.scikit_learn import KerasClassifier, KerasRegressor
    import eli5
    from eli5.sklearn import PermutationImportance

    # Define your model
    def base_model():
        model = Sequential()
        model.add(Dense(200, input_dim=10, activation='relu'))
        model.add(Dense(3, activation='softmax'))  # Assuming 3 categories
        model.compile(loss='categorical_crossentropy', optimizer='adam')
        return model

    # Fit your model
    X = ...  # Your input features
    y = ...  # Your target labels
    my_model = KerasRegressor(build_fn=base_model, epochs=100, batch_size=5, verbose=0)
    my_model.fit(X, y)

    # Calculate permutation importance
    perm = PermutationImportance(my_model, random_state=1).fit(X, y)
    eli5.show_weights(perm, feature_names=['Feature 1', 'Feature 2', ..., 'Feature 10'])
    ```

    <big>**SHAP Values**</big>

    SHAP values provide a way to understand the contribution of each feature to the model’s predictions. [It is based on game theory and calculates the contribution of each feature to the prediction of each instance in comparison to the average prediction for the dataset](https://aitechtrend.com/a-guide-to-explaining-feature-importance-in-neural-networks-using-shap/) [`²`](https://aitechtrend.com/a-guide-to-explaining-feature-importance-in-neural-networks-using-shap/).

    Here’s a simple example of how to use SHAP with a neural network:

    ```python
    import shap

    # Assume 'model' is your trained Keras model and 'X' is your input data

    # Explain predictions using SHAP
    explainer = shap.DeepExplainer(model, X)
    shap_values = explainer.shap_values(X)

    # Plot the SHAP values for the first instance
    shap.initjs()
    shap.force_plot(explainer.expected_value[0], shap_values[0][0], X.iloc[0])
    ```

    Both methods can give you insights into which dimensions (features) are most important for your deep neural network’s classification decisions. Remember to carefully interpret the results, as the importance of features can depend on the model and the specific data you are working with.

    了解详细信息 [`1 | stackoverflow.com`](https://stackoverflow.com/questions/45361559/feature-importance-chart-in-neural-network-using-keras-in-python) [`2 | aitechtrend.com`](https://aitechtrend.com/a-guide-to-explaining-feature-importance-in-neural-networks-using-shap/) [`3 | machinelearningmastery.com`](https://machinelearningmastery.com/calculate-feature-importance-with-python/) [`4 | datascience.stackexchange.com`](https://datascience.stackexchange.com/questions/44644/how-to-determine-feature-importance-in-a-neural-network) [`5 | stats.stackexchange.com`](https://stats.stackexchange.com/questions/261008/deep-learning-how-do-i-know-which-variables-are-important)
