---
draft: true
date: 2024-04-16
authors:
  - ronald_luo
categories:
  - Records of Trivia
comments: true
---

# 2024 RoboCup@Home *What is that* 项目准备记录

由于这个项目需要识别出手指向物体👉的手势，所以就在网上查找实现了相关功能的现成的库，

## 查阅MediaPipe库说明

于是查到谷歌的MediaPipe库中有手势识别的功能，

<!-- more -->

>   -   [Gesture recognition task guide  | MediaPipe  | Google for Developers](https://developers.google.cn/mediapipe/solutions/vision/gesture_recognizer)
>   -   [Hand landmarks detection guide  | MediaPipe  | Google for Developers](https://developers.google.cn/mediapipe/solutions/vision/hand_landmarker)
>
>   >   手势识别功能的**python示例代码(只识别图片)**和**web示例(调用摄像头实时视频识别)**
>   >
>   >   -   [gesture_recognizer.ipynb - Colab (google.com)](https://colab.research.google.com/github/googlesamples/mediapipe/blob/main/examples/gesture_recognizer/python/gesture_recognizer.ipynb#scrollTo=O6PN9FvIx614)
>   >   -   [MediaPipe HandGestureRecognizer Task for web (codepen.io)](https://codepen.io/mediapipe-preview/pen/zYamdVd)

然后尝试运行python示例代码并安装相应的环境，

一番操作后能成功运行代码并在图像上显示手的关键点。

---

## github开源手势识别仓库

[在github上搜索手势识别相关的开源仓库](https://github.com/search?q=gesture+recognition+&type=repositories)，然后发现一个说明用日文写的使用mediapipe来进行手势识别的仓库

!!! info

    [Kazuhito00/hand-gesture-recognition-using-mediapipe: MediaPipe(Python版)を用いて手の姿勢推定を行い、検出したキーポイントを用いて、簡易なMLPでハンドサインとフィンガージェスチャーを認識するサンプルプログラムです。（Estimate hand pose using MediaPipe(Python version). This is a sample program that recognizes hand signs and finger gestures with a simple MLP using the detected key points.） (github.com)](https://github.com/Kazuhito00/hand-gesture-recognition-using-mediapipe)

克隆并尝试运行 `app.py` ，发现没有tensorflow，然后安装tensorflow后就能正常运行了，

>   神奇的是，我已安装的python包的版本基本上都高于 `requirements.txt` 中的包版本，但还是可以运行😄

发现这个仓库可以识别到指👉的手势(各个方向都可以，直接使用mediapipe似乎只能识别指向上的手势)，**并特别显示指尖的关键点**，所以感觉很符合What is that项目的要求，

于是开始理解 `app.py` 中的代码，

借助copilot来解释 `app.py` 中的 `main()` 函数

???+ example "对话记录"

    SeazSu: `@workspace` `/explain` 
    
    GitHub Copilot:
    
    ??? quote "已使用 1 引用"
    
        - app.py: 41-181
    
    这段代码是一个手势识别程序的主要部分。它使用了OpenCV和MediaPipe库来捕获和处理视频帧，以识别和跟踪手的位置和手势。
    
    首先，代码通过`get_args()`函数获取命令行参数，这些参数包括设备ID、图像宽度和高度、是否使用静态图像模式以及最小检测和跟踪置信度等。然后，使用这些参数初始化一个OpenCV的`VideoCapture`对象，用于从指定设备捕获视频。
    
    接下来，代码加载了MediaPipe的手部解决方案模型，并创建了一个`Hands`对象。这个对象会用于后续的手部关键点检测。同时，还初始化了两个分类器，一个用于关键点分类，另一个用于点历史分类。
    
    然后，代码从CSV文件中读取了关键点分类器和点历史分类器的标签。这些标签将用于后续的手势识别。
    
    在主循环中，代码首先获取当前的FPS值，然后检测是否按下了ESC键。如果按下了ESC键，程序将退出。然后，代码从`VideoCapture`对象中读取一帧图像，并将其翻转，以实现镜像显示。
    
    接着，代码将图像从BGR格式转换为RGB格式，并将其传递给`Hands`对象进行处理。如果在图像中检测到了手，`Hands`对象将返回一个包含手部关键点的结果。
    
    对于检测到的每一只手，代码首先计算其外接矩形和关键点列表，然后对关键点列表和点历史进行预处理，并保存学习数据。然后，代码使用关键点分类器对预处理后的关键点列表进行分类，如果检测到了指向手势，就将人指关键点添加到点历史中，否则添加[0,0]。
    
    然后，代码检查点历史的长度，如果长度等于历史长度的两倍，就使用点历史分类器对预处理后的点历史进行分类。然后，代码将分类结果添加到手势历史中，并计算最常见的手势ID。
    
    最后，代码将外接矩形、关键点、信息文本等绘制到图像上，并显示图像。当退出主循环后，代码释放`VideoCapture`对象，并销毁所有OpenCV窗口。

发现 `main` 中的 *主循环* 部分代码的结构大致是这样

```python title="app.py"
while True:
    
    ### 获取图像并进行处理和识别，
    ### 将识别结果保存在 result 中，
    ### 如果检测到按ESC键则退出程序

    #  ####################################################################
    if results.multi_hand_landmarks is not None:
        for hand_landmarks, handedness in zip(results.multi_hand_landmarks,
                                              results.multi_handedness):
            ### 如果识别到手，进行一些处理

            ### 如果识别到是指的手势(hand_sign_id 值为 2)，
            ### 就将指尖的坐标添加到历史关键点列表中
            
            # ハンドサイン分類
            hand_sign_id = keypoint_classifier(pre_processed_landmark_list)
            if hand_sign_id == 2:  # 指差しサイン
                point_history.append(landmark_list[8])  # 人差指座標
            else:
                point_history.append([0, 0])

            ### 剩余的一些其他处理
            
    else:
        point_history.append([0, 0])

    debug_image = draw_point_history(debug_image, point_history)
    debug_image = draw_info(debug_image, fps, mode, number)

    # 画面反映 #############################################################
    cv.imshow('Hand Gesture Recognition', debug_image)
```

---

## github上23年RoboCup@Home *What is that* 项目实现代码仓库

在[bing上搜索](https://www.bing.com/search?pglt=131&q=robocup+家政+what's+that&cvid=f0e6138aeb74424e867b348d21a7aa02&gs_lcrp=EgZjaHJvbWUyBggAEEUYOdIBCTE1NzE3ajBqMagCCLACAQ&FORM=ANNTA1&adppc=EdgeStart&PC=NMTS&mkt=zh-CN)时，无意中发现github上有一个仓库存了作者23年完成what is that题目(以及一些其他题目的)，

[JeexiongRen/RoboCup-home-What-is-that (github.com)](https://github.com/JeexiongRen/RoboCup-home-What-is-that)

